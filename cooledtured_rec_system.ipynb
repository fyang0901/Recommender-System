{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Websites for Anime\n",
        "1. MyAnimeList (Where the data was extracted) - https://myanimelist.net/\n",
        "2. Jikan API (Tool used to extract data from MAL) - https://jikan.moe/\n",
        "3. JikanPy (Python Wrapper for Jikan, includes GitHub and documentation) - https://github.com/abhinavk99/jikanpy"
      ],
      "metadata": {
        "id": "fGz83bBvD0NO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cooledtured Anime Recommender System"
      ],
      "metadata": {
        "id": "hBiCDMLlErUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "1. Before running this code, you will need two files to upload onto this colab.\n",
        "    - **client_secret_407060465423-3r8r7du6bg9l4gpivsiqrmas6cj8voru.apps.googleusercontent.com.json**\n",
        "    - **peak-castle-454322-n7-b67cde6c3167.json**\n",
        "    - *These files are located in the Google Drive via Recommendation System -> Anime RecSystem Required Files (https://drive.google.com/drive/u/1/folders/1Zxd0uJxAkPma1ZJ_X628ULP8krwRNQVj)*\n",
        "    - *These files will give you access to the database stored within cooledtured's google sheets drive*\n",
        "    - *NOTE: Everytime you want to run this model, you need to always upload these files to the colab since Google disconnects and deletes these files after an extended amount of time*\n",
        "2. The first section of this colab (Installing Required Packages) is to install the packages required to run the model. The colab *should* already have these packages installed through previous attempts in running the file; but, just run all the lines starting with \"!pip\" just in case.\n",
        "3. The second section of this colab (Getting Access to Model/Dashboard) is to run all the lines of code s.t. you are able to access a working dashboard which is able to recommend animes from MyAnimeList's \"Top Anime\" section.\n",
        "    - The code creates a new file called tab1_top_anime_data.csv. Do not worry about this file, this is used by the model.\n",
        "    - The database does not include *every* anime from MyAnimeList's database, but it does include a substantial amount (10,000+ Animes). This should be suitable for recommendation and for the initiatives relating to cooledtured.\n",
        "    - At the bottom of this section, there should be a new dashboard where you can enter any Anime you want with several filtering options. Have fun trying it out!\n",
        "    - *NOTE: The dashboard also includes a new \"public URL\" which you can click to get a larger screen of the dashboard. This link will only last up until the colab disconnects (i.e. not running the code in this file for an extended amount of time).*"
      ],
      "metadata": {
        "id": "wCky037UE6TI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Potential Errors\n",
        "1. There may be an error that tells you that one of two files do not exist:\n",
        "    - client_secret_407060465423-3r8r7du6bg9l4gpivsiqrmas6cj8voru.apps.googleusercontent.com.json\n",
        "    - peak-castle-454322-n7-b67cde6c3167.json\n",
        "- **This means that you did not upload the files!!!!** Make sure to upload them before running this code."
      ],
      "metadata": {
        "id": "v_JknyfLKmN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Documentation for Anime RecSystem\n",
        "### (Includes everything mentioned above + more)\n",
        "https://docs.google.com/document/d/1TYxpXEpBzYitrHQUjruQqaQRtexd6kSF-8qRUvOb8n4/edit?usp=sharing"
      ],
      "metadata": {
        "id": "8oNODUnHMeQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Required Packages"
      ],
      "metadata": {
        "id": "3aK7zFkgGbmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcoMY3SGBU-_",
        "outputId": "47b97dda-6d4f-4d1e-9bf6-7a9d72f1f1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jikanpy-v4\n",
            "  Downloading jikanpy_v4-1.0.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from jikanpy-v4) (2.32.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from jikanpy-v4) (3.11.15)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from jikanpy-v4) (3.20.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jikanpy-v4) (1.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->jikanpy-v4) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->jikanpy-v4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->jikanpy-v4) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->jikanpy-v4) (2025.6.15)\n",
            "Downloading jikanpy_v4-1.0.2-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: jikanpy-v4\n",
            "Successfully installed jikanpy-v4-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install jikanpy-v4 # documentaton: https://jikanpy.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib gspread"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCG_s_sCCBWB",
        "outputId": "31ce5fc6-0a2d-47f6-c618-c944e65004a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.174.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.175.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.38.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.6.15)\n",
            "Downloading google_api_python_client-2.175.0-py3-none-any.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-api-python-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.174.0\n",
            "    Uninstalling google-api-python-client-2.174.0:\n",
            "      Successfully uninstalled google-api-python-client-2.174.0\n",
            "Successfully installed google-api-python-client-2.175.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sEmg7DaCBxJ",
        "outputId": "6041d4f8-c58a-4799-9d48-3bcd208e9b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY7irx4ICOsL",
        "outputId": "d00c4df9-3cc0-4e25-f13f-5c7a8803d447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Access to Model/Dashboard"
      ],
      "metadata": {
        "id": "8y1usg9THVNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jikanpy import Jikan # For MyAnimeList\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2.service_account import Credentials\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import gradio as gr\n",
        "\n",
        "SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']\n",
        "creds = Credentials.from_service_account_file('peak-castle-454322-n7-b67cde6c3167.json', scopes=SCOPES)\n",
        "client = gspread.authorize(creds)\n",
        "sheet = client.open_by_key('14rlMEGcS52vgP_BrFYPlQ-q_iFL2GXJng1tPxb3Vj38')"
      ],
      "metadata": {
        "id": "8w7sTVeACN4h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "a1e377fc-0882-4285-b421-aca35a58aed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'peak-castle-454322-n7-b67cde6c3167.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3708176066.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mSCOPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'https://www.googleapis.com/auth/spreadsheets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https://www.googleapis.com/auth/drive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_service_account_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'peak-castle-454322-n7-b67cde6c3167.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSCOPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'14rlMEGcS52vgP_BrFYPlQ-q_iFL2GXJng1tPxb3Vj38'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/oauth2/service_account.py\u001b[0m in \u001b[0;36mfrom_service_account_file\u001b[0;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         info, signer = _service_account_info.from_filename(\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"client_email\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_uri\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/auth/_service_account_info.py\u001b[0m in \u001b[0;36mfrom_filename\u001b[0;34m(filename, require, use_rsa_signer)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0msigner\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \"\"\"\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_rsa_signer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_rsa_signer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'peak-castle-454322-n7-b67cde6c3167.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleSheet:\n",
        "    def __init__(self, credentials_file, sheet_id, sheet_tab=0):\n",
        "        \"\"\"\n",
        "        Initialize the GoogleSheet connection.\n",
        "\n",
        "        :param credentials_file: Path to the Google service account credentials.\n",
        "        :param sheet_id: Google Sheet ID.\n",
        "        :param sheet_tab: Sheet tab name or index (default is 0, the first sheet).\n",
        "        \"\"\"\n",
        "        self.credentials_file = credentials_file\n",
        "        self.sheet_id = sheet_id\n",
        "        self.sheet_tab = sheet_tab\n",
        "        self.client = None\n",
        "        self.sheet = None\n",
        "\n",
        "    def __enter__(self):\n",
        "        \"\"\"Establish the connection when entering the context.\"\"\"\n",
        "        creds = Credentials.from_service_account_file(self.credentials_file, scopes=SCOPES)\n",
        "        self.client = gspread.authorize(creds)\n",
        "        spreadsheet = self.client.open_by_key(self.sheet_id)\n",
        "\n",
        "        # Select the sheet tab (by index or name)\n",
        "        if isinstance(self.sheet_tab, int):\n",
        "            self.sheet = spreadsheet.get_worksheet(self.sheet_tab)  # Select by index (0-based)\n",
        "        else:\n",
        "            self.sheet = spreadsheet.worksheet(self.sheet_tab)  # Select by name\n",
        "\n",
        "        return self\n",
        "\n",
        "    def get_data(self):\n",
        "        \"\"\"Fetch all data from the selected sheet tab.\"\"\"\n",
        "        return self.sheet.get_all_values()\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        \"\"\"Handle cleanup if needed.\"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "xrFaR_1fC1w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_csv(data, filename):\n",
        "    \"\"\"Save list of lists (Google Sheet data) to a CSV file.\"\"\"\n",
        "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerows(data)\n",
        "\n",
        "# Define credentials and sheet details\n",
        "credentials_file = 'peak-castle-454322-n7-b67cde6c3167.json'\n",
        "sheet_id = '14rlMEGcS52vgP_BrFYPlQ-q_iFL2GXJng1tPxb3Vj38'\n",
        "tab_name_or_index = 0\n",
        "\n",
        "with GoogleSheet(credentials_file, sheet_id, tab_name_or_index) as gs:\n",
        "    data = gs.get_data()\n",
        "\n",
        "save_to_csv(data, 'tab1_top_anime_data.csv')\n",
        "print(\"CSV file saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr3iVvsbDGUF",
        "outputId": "b9d23fbf-9c82-419d-b80b-10251ff0113e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Reccomender for top anime\n",
        "'''\n",
        "# Step 1: Load and clean base DataFrame\n",
        "df = pd.read_csv(\"tab1_top_anime_data.csv\")\n",
        "df['genres'] = df['genres'].fillna('')\n",
        "df['synopsis'] = df['synopsis'].fillna('')\n",
        "df['rating'] = df['rating'].fillna('Unknown')\n",
        "\n",
        "# Step 2: Normalize rating labels\n",
        "rating_map = {\n",
        "    'G - All Ages': 'G',\n",
        "    'PG - Children': 'PG',\n",
        "    'PG-13 - Teens 13 or older': 'PG-13',\n",
        "    'R - 17+ (violence & profanity)': 'R',\n",
        "    'R+ - Mild Nudity': 'R+',\n",
        "    'Rx - Hentai': 'Rx'\n",
        "}\n",
        "df[\"rating_clean\"] = df[\"rating\"].map(rating_map)\n",
        "\n",
        "# Step 3: Filter function\n",
        "def filter_by_rating(dataframe, allowed_ratings):\n",
        "    return dataframe[dataframe['rating_clean'].isin(allowed_ratings)]\n",
        "\n",
        "# Step 4: Apply rating filter before computing TF-IDF\n",
        "filtered_df = filter_by_rating(df, ['PG-13', 'R', 'G', 'PG', 'R+', 'Rx'])\n",
        "\n",
        "# Step 5: Combine genres and synopsis for content\n",
        "filtered_df['content'] = filtered_df['genres'] + \" \" + filtered_df['synopsis']\n",
        "\n",
        "# Step 6: Compute TF-IDF and Cosine Similarity on filtered data\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(filtered_df['content'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Step 7: Recommender function\n",
        "def get_filtered_recommendations(title, df, cosine_sim, min_score=7, min_popularity=1000, base_type=\"N/A\", base_rating=\"N/A\"):\n",
        "    title_lower = title.lower()\n",
        "\n",
        "    # Match by original or English title\n",
        "    match_idx = df[df['title'].str.lower() == title_lower].index\n",
        "    if match_idx.empty:\n",
        "        match_idx = df[df['title_english'].str.lower() == title_lower].index\n",
        "\n",
        "    if match_idx.empty:\n",
        "        return f\"Anime '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = match_idx[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    anime_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    filtered_anime = df.iloc[anime_indices].copy()\n",
        "\n",
        "    # Apply filtering\n",
        "    if base_type != \"N/A\":\n",
        "        filtered_anime = filtered_anime[filtered_anime['type'] == base_type]\n",
        "    if base_rating != \"N/A\":\n",
        "        filtered_anime = filtered_anime[filtered_anime['rating_clean'] == base_rating]\n",
        "\n",
        "    filtered_anime = filtered_anime[(filtered_anime['score'] >= min_score) &\n",
        "                                    (filtered_anime['popularity'] < min_popularity)]\n",
        "\n",
        "    # Exclude the base anime\n",
        "    filtered_anime = filtered_anime[~filtered_anime['title'].str.lower().str.contains(title_lower, regex=False)]\n",
        "    filtered_anime = filtered_anime[~filtered_anime['title_english'].str.lower().str.contains(title_lower, regex=False, na=False)]\n",
        "\n",
        "    # Trending score\n",
        "    filtered_anime['trending_score'] = (\n",
        "        0.2 * filtered_anime['score'] +\n",
        "        0.4 * filtered_anime['favorites'] +\n",
        "        0.4 * (1 / (filtered_anime['popularity'] + 1))\n",
        "    )\n",
        "\n",
        "    return filtered_anime[['title', 'title_english', 'genres', 'score', 'rating_clean', 'type', 'popularity', 'trending_score']].head(10)\n",
        "\n",
        "# Step 8: Example usage\n",
        "filtered_recommendations = get_filtered_recommendations(\"Your Name.\", filtered_df, cosine_sim, base_type=\"TV\", base_rating=\"R\")\n",
        "print(filtered_recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KCQQMXlDLuq",
        "outputId": "46462885-9532-4fc7-a363-7a8675e504d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-899c58bf6d27>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['content'] = filtered_df['genres'] + \" \" + filtered_df['synopsis']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         title  \\\n",
            "548                                 Durarara!!   \n",
            "1609                            Gakkougurashi!   \n",
            "122                     Yojouhan Shinwa Taikei   \n",
            "1700                             Kekkai Sensen   \n",
            "1859                                      No.6   \n",
            "19          Code Geass: Hangyaku no Lelouch R2   \n",
            "236   Mushoku Tensei: Isekai Ittara Honki Dasu   \n",
            "827          Full Metal Panic! The Second Raid   \n",
            "942                            Tokyo Revengers   \n",
            "2783                    Toaru Majutsu no Index   \n",
            "\n",
            "                                title_english  \\\n",
            "548                                Durarara!!   \n",
            "1609                             School-Live!   \n",
            "122                         The Tatami Galaxy   \n",
            "1700               Blood Blockade Battlefront   \n",
            "1859                                    No. 6   \n",
            "19    Code Geass: Lelouch of the Rebellion R2   \n",
            "236     Mushoku Tensei: Jobless Reincarnation   \n",
            "827         Full Metal Panic! The Second Raid   \n",
            "942                           Tokyo Revengers   \n",
            "2783                  A Certain Magical Index   \n",
            "\n",
            "                                                 genres  score rating_clean  \\\n",
            "548                       Action, Mystery, Supernatural   8.09            R   \n",
            "1609           Horror, Mystery, Slice of Life, Suspense   7.61            R   \n",
            "122   Award Winning, Comedy, Mystery, Romance, Suspense   8.55            R   \n",
            "1700                                    Action, Fantasy   7.59            R   \n",
            "1859                     Action, Drama, Mystery, Sci-Fi   7.55            R   \n",
            "19                 Action, Award Winning, Drama, Sci-Fi   8.91            R   \n",
            "236                    Adventure, Drama, Fantasy, Ecchi   8.36            R   \n",
            "827                                              Action   7.91            R   \n",
            "942                                       Action, Drama   7.86            R   \n",
            "2783                            Action, Fantasy, Sci-Fi   7.34            R   \n",
            "\n",
            "     type  popularity  trending_score  \n",
            "548    TV          94    12055.622211  \n",
            "1609   TV         516     2240.722774  \n",
            "122    TV         512     7494.910780  \n",
            "1700   TV         203     3259.919961  \n",
            "1859   TV         543     2980.310735  \n",
            "19     TV          47    31387.390333  \n",
            "236    TV          93    14835.676255  \n",
            "827    TV         977      521.582409  \n",
            "942    TV         105    10101.575774  \n",
            "2783   TV         238     2267.469674  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "# Make sure these are defined globally before the interface is launched\n",
        "# df = ...  # Your full anime dataset\n",
        "# cosine_sim = ...  # Your similarity matrix\n",
        "\n",
        "# Safely wrap the function to capture errors and debug\n",
        "def recommend_interface(title, min_score, min_popularity, base_type, base_rating):\n",
        "    try:\n",
        "        result = get_filtered_recommendations(\n",
        "            title,\n",
        "            df=df,\n",
        "            cosine_sim=cosine_sim,\n",
        "            min_score=min_score,\n",
        "            min_popularity=min_popularity,\n",
        "            base_type=base_type,\n",
        "            base_rating=base_rating\n",
        "        )\n",
        "        if result is None or result.empty:\n",
        "            return pd.DataFrame([{\"Message\": \"No recommendations found.\"}])\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return pd.DataFrame([{\"Error\": str(e)}])\n",
        "\n",
        "# Inputs\n",
        "inputs = [\n",
        "    gr.Textbox(label=\"Anime Title\"),\n",
        "    gr.Slider(minimum=0, maximum=10, step=0.1, value=7, label=\"Minimum Score\"),\n",
        "    gr.Number(value=1000, label=\"Maximum Popularity\"),\n",
        "    gr.Textbox(label=\"Base Type (e.g., TV, TV Special, Movie, OVA, Music, ONA, Special, PV, CM, N/A)\", placeholder=\"N/A\"),\n",
        "    gr.Textbox(label=\"Base Rating (e.g., PG-13, R, R+, PG, G, Rx, N/A)\", placeholder=\"N/A\")\n",
        "]\n",
        "\n",
        "# Interface\n",
        "gr.Interface(\n",
        "    fn=recommend_interface,\n",
        "    inputs=inputs,\n",
        "    outputs=gr.Dataframe(),\n",
        "    title=\"Anime Recommender System\",\n",
        "    description=\"Search for anime recommendations with customizable filters!\"\n",
        ").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "0gPbOoyIDd2F",
        "outputId": "e2999a8c-60f4-4acd-8088-3a6fabeb02eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b0af73d1c2602e6646.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b0af73d1c2602e6646.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommendation System"
      ],
      "metadata": {
        "id": "_sdkRvha-Hlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instructions**\n",
        "\n",
        "Before running this notebook, upload one essential file:  \n",
        "**`optimum-web-454302-e0-f5b48548795c.json`**\n",
        "\n",
        "* This file allows the script to connect and write to a Google Sheet using the `gspread` library.\n",
        "* **Important:** Youâ€™ll need to re-upload this file each time you reconnect to Colab, because uploaded files are cleared when your session ends.\n",
        "\n",
        "---\n",
        "\n",
        "# **Library Setup and Authorization**\n",
        "\n",
        "* Installs required packages and authorizes access to Google Sheets and the TMDB API.\n",
        "* Imports libraries, loads your credentials, and links to the appropriate Google Sheet via its key.\n",
        "\n",
        "---\n",
        "\n",
        "# **Retrieving Genre Info**\n",
        "\n",
        "* Uses the TMDB API to fetch genre mappings for both movies and TV series.\n",
        "* These mappings are used to convert numerical genre IDs into readable genre names.\n",
        "\n",
        "---\n",
        "\n",
        "# **Utility Functions for Data Retrieval**\n",
        "\n",
        "* Checks if a specific worksheet already exists, or creates it if it doesn't.\n",
        "* Pulls the top 3 actors and any listed directors for a given movie or show using its TMDB ID.\n",
        "\n",
        "---\n",
        "\n",
        "# **Getting Popular Titles from TMDB**\n",
        "\n",
        "* Calls TMDBâ€™s API for popular movies and shows, scanning up to 500 pages for each category.\n",
        "* Gathers details like:\n",
        "  * Title\n",
        "  * ID\n",
        "  * Release Date\n",
        "  * Rating\n",
        "  * Genres\n",
        "  * Summary\n",
        "  * Cast\n",
        "  * Crew\n",
        "* Results are automatically sorted from most to least popular.\n",
        "\n",
        "---\n",
        "\n",
        "# **Sending Data to Google Sheets**\n",
        "\n",
        "* Merges the collected movie and show data, then uploads it to the Google Sheet.\n",
        "* Data is written into a tab named **\"Ranked Content\"** and includes the following columns:\n",
        "\n",
        "| **Column**         | **Description** |\n",
        "|:-------------------|:----------------|\n",
        "| **Title**          | Name of the movie or TV show |\n",
        "| **Content ID**     | TMDB ID |\n",
        "| **Release Date**   | Date released |\n",
        "| **Rating**         | Average TMDB rating |\n",
        "| **Genre**          | Genre(s) as text |\n",
        "| **Popularity**     | TMDB popularity metric |\n",
        "| **Synopsis**       | Short description |\n",
        "| **Content Link**   | Clickable TMDB link |\n",
        "| **Type**           | Movie or TV Show |\n",
        "| **Top 3 Actors**   | Leading cast members |\n",
        "| **Directors**      | Director(s) |\n",
        "\n",
        "**Note:** Depending on your connection and TMDBâ€™s rate limits, the upload process may take several minutes.\n",
        "\n",
        "---\n",
        "\n",
        "# **Launching the Gradio Interface**\n",
        "\n",
        "Creates an interactive app that lets users:\n",
        "\n",
        "* Search for any title and view content-based recommendations.\n",
        "* Filter results by:\n",
        "  * Minimum rating\n",
        "  * Content type (Movie, TV Show, or Both)\n",
        "  * Genre\n",
        "* Explore two types of recommendations:\n",
        "  * Content-based (based on synopsis and genre)\n",
        "  * Cast-based (based on shared actors or directors)\n",
        "\n",
        "**Tip:** If nothing shows up, try searching for a more common or exact title name.\n",
        "\n",
        "---\n",
        "\n",
        "# **Potential Errors**\n",
        "\n",
        "* **If it doesn't run, its because the files may not have been downloaded. Make sure to download!**\n",
        "* Sometimes, titles may have unique characters, like \"Ã©\". This may not generate results, you must get the exact title in that case\n",
        "* Sometimes, because of how many movies and shows there are, we simply weren't able to retrieve the movie.\n"
      ],
      "metadata": {
        "id": "TaaM50cl-KW-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Websites for Movies\n",
        "\n",
        "1. TMDB (Where the data was extracted) - https://www.themoviedb.org/?language=en-US\n",
        "2. TMDB API Key - 'b8efb431ca874795fa3bd90a9216e38b'\n",
        "3. TMDB - \"https://api.themoviedb.org/3/genre/{content_type}/list?api_key=\n",
        "{api_key}&language=en-US\"\n",
        "\n",
        "Google Sheets API Key: 1ztcWL119qy67Ox7JsHp1cmiQ158yJ9abKlfAjUj6_AY"
      ],
      "metadata": {
        "id": "uriDn49xTl3A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "exz-xSnIZIdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from difflib import get_close_matches\n",
        "\n",
        "# ðŸ”— Google Sheet CSV URL\n",
        "google_sheet_url = \"https://docs.google.com/spreadsheets/d/1ztcWL119qy67Ox7JsHp1cmiQ158yJ9abKlfAjUj6_AY/export?format=csv&gid=1096224009\"\n",
        "df = pd.read_csv(google_sheet_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ximAV5ygZvoc",
        "outputId": "e9c64afe-891b-44e4-d010-b566e619ab1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.28.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.28.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.28.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Required Packages"
      ],
      "metadata": {
        "id": "Ij7C9PvUeIIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommender System"
      ],
      "metadata": {
        "id": "cpDti5Zr7utl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "oS-MDSUwfVoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da2bc8d-38c0-49d0-f2df-007994a2c2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.27.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.9.0 (from gradio)\n",
            "  Downloading gradio_client-1.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.27.0-py3-none-any.whl (54.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.9.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.6/322.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.27.0 gradio-client-1.9.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.7 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sckit-\n"
      ],
      "metadata": {
        "id": "sM3SzGPBf0Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059ef7ef-8375-4413-cbad-5eaed282831d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'sckit-': Expected end or semicolon (after name and no valid version specifier)\n",
            "    sckit-\n",
            "         ^\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping the data"
      ],
      "metadata": {
        "id": "XRzLeU8MgslR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Will take hours to compile\n",
        "\n",
        "import requests\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime\n",
        "\n",
        "# TMDB API Key\n",
        "api_key = 'b8efb431ca874795fa3bd90a9216e38b'\n",
        "\n",
        "# Google Sheets setup\n",
        "scope = [\"https://spreadsheets.google.com/feeds\",\n",
        "         \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\",\n",
        "         \"https://www.googleapis.com/auth/drive\"]\n",
        "\n",
        "# Load credentials\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(\n",
        "    r\"C:\\Users\\12407\\Downloads\\optimum-web-454302-e0-f5b48548795c.json\", scope\n",
        ")\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet\n",
        "spreadsheet = client.open_by_key(\"1ztcWL119qy67Ox7JsHp1cmiQ158yJ9abKlfAjUj6_AY\")\n",
        "\n",
        "# Function to check if a sheet exists or create a new one\n",
        "def get_or_create_sheet(spreadsheet, sheet_name, headers):\n",
        "    try:\n",
        "        sheet = spreadsheet.worksheet(sheet_name)\n",
        "        print(f\"Found sheet: {sheet_name}.\")\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        sheet = spreadsheet.add_worksheet(title=sheet_name, rows=\"10000\", cols=\"11\")  # Update to 11 columns for new data\n",
        "        print(f\"Created new sheet: {sheet_name}.\")\n",
        "\n",
        "    # Clear the sheet before updating it\n",
        "    sheet.clear()\n",
        "    sheet.insert_row(headers, 1)\n",
        "    return sheet\n",
        "\n",
        "# Function to get genre dictionary\n",
        "def get_genres(content_type):\n",
        "    url = f\"https://api.themoviedb.org/3/genre/{content_type}/list?api_key={api_key}&language=en-US\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        genres = {genre['id']: genre['name'] for genre in response.json().get('genres', [])}\n",
        "        return genres\n",
        "    else:\n",
        "        print(f\"Failed to fetch {content_type} genres. Status: {response.status_code}\")\n",
        "        return {}\n",
        "\n",
        "# Fetch movie and TV genres\n",
        "movie_genres = get_genres(\"movie\")\n",
        "tv_genres = get_genres(\"tv\")\n",
        "\n",
        "# Function to get actors and directors for a specific content ID (movie or TV show)\n",
        "def get_actors_and_directors(content_type, content_id):\n",
        "    url = f\"https://api.themoviedb.org/3/{content_type}/{content_id}/credits?api_key={api_key}&language=en-US\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        # Get top 3 actors\n",
        "        actors = [actor['name'] for actor in data.get('cast', [])[:3]]  # Adjust the number of actors as needed\n",
        "        # Get director(s)\n",
        "        directors = [crew['name'] for crew in data.get('crew', []) if crew['job'] == 'Director']\n",
        "        return \", \".join(actors), \", \".join(directors)\n",
        "    else:\n",
        "        print(f\"Failed to fetch credits for {content_type} with ID {content_id}. Status: {response.status_code}\")\n",
        "        return \"\", \"\"  # Return empty strings if unable to fetch\n",
        "\n",
        "# Function to fetch popular content with actors and directors\n",
        "def fetch_popular_content_with_actors_and_directors(url, content_type, genres, pages=50):\n",
        "    items = []\n",
        "\n",
        "    for page in range(1, pages + 1):\n",
        "        print(f\"Fetching page {page} for {content_type}...\")\n",
        "        response = requests.get(f\"{url}&page={page}\")\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            for item in data.get('results', []):\n",
        "                title = item.get('title', item.get('name', 'Unknown'))\n",
        "                content_id = item.get('id', 'N/A')\n",
        "                release_date = item.get('release_date') if content_type == \"movie\" else item.get('first_air_date')\n",
        "                rating = item.get('vote_average', 'N/A')\n",
        "                popularity = item.get('popularity', 0)\n",
        "                genre_ids = item.get('genre_ids', [])\n",
        "                genre_names = \", \".join([genres.get(gid, \"Unknown\") for gid in genre_ids])\n",
        "                synopsis = item.get('overview', 'No synopsis available.')\n",
        "                content_link = f\"https://www.themoviedb.org/{content_type}/{content_id}\"\n",
        "\n",
        "                # Get actors and directors\n",
        "                actors, directors = get_actors_and_directors(content_type, content_id)\n",
        "\n",
        "                # Add content type (movie or tv)\n",
        "                content_type_label = \"movie\" if content_type == \"movie\" else \"tv show\"\n",
        "                items.append([title, content_id, release_date or 'N/A', rating, genre_names, popularity, synopsis, content_link, content_type_label, actors, directors])\n",
        "        else:\n",
        "            print(f\"Failed to get {content_type} data. Status: {response.status_code}\")\n",
        "            break  # Stop if any request fails\n",
        "\n",
        "    return items\n",
        "\n",
        "# Get or create the sheet for ranked movies and TV shows with actors and directors columns\n",
        "ranked_content_sheet = get_or_create_sheet(spreadsheet, \"Ranked Content\",\n",
        "                                           [\"Title\", \"Content ID\", \"Release Date\", \"Rating\", \"Genre\", \"Popularity\", \"Synopsis\", \"Content Link\", \"Type\", \"Actors\", \"Directors\"])\n",
        "\n",
        "# Fetch and store popular movies (up to 50 pages)\n",
        "popular_movies_url = f\"https://api.themoviedb.org/3/movie/popular?api_key={api_key}&language=en-US\"\n",
        "popular_movies_data = fetch_popular_content_with_actors_and_directors(popular_movies_url, \"movie\", movie_genres, pages=500)\n",
        "\n",
        "# Fetch and store popular TV shows (up to 50 pages)\n",
        "popular_tv_url = f\"https://api.themoviedb.org/3/tv/popular?api_key={api_key}&language=en-US\"\n",
        "popular_tv_data = fetch_popular_content_with_actors_and_directors(popular_tv_url, \"tv\", tv_genres, pages=500)\n",
        "\n",
        "# Combine movies and TV shows data\n",
        "combined_data = popular_movies_data + popular_tv_data\n",
        "\n",
        "# Sort combined data by popularity\n",
        "combined_data.sort(key=lambda x: x[5], reverse=True)\n",
        "\n",
        "# Insert data into the sheet\n",
        "if combined_data:\n",
        "    ranked_content_sheet.append_rows(combined_data)\n",
        "\n",
        "print(\"Ranked Movies and TV Shows have been updated successfully!\")\n"
      ],
      "metadata": {
        "id": "5ilnzY3igwDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the Recommendations + Gradio"
      ],
      "metadata": {
        "id": "8ujT2C9LjdVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "yA7sTxzYU10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929f8e95-6844-44e4-d263-928e7773cc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.28.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.10.0 (from gradio)\n",
            "  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.17)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.28.0-py3-none-any.whl (54.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.28.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load dataset from Google Sheets\n",
        "google_sheet_url = \"https://docs.google.com/spreadsheets/d/1ztcWL119qy67Ox7JsHp1cmiQ158yJ9abKlfAjUj6_AY/export?format=csv&gid=1096224009\"\n",
        "df = pd.read_csv(google_sheet_url)\n",
        "\n",
        "# Fill missing values\n",
        "df.fillna('', inplace=True)\n",
        "\n",
        "# Normalize genres\n",
        "def normalize_genres(genre_str):\n",
        "    separators = [\",\", \"|\", \"/\", \";\"]\n",
        "    genre_str = genre_str.lower()\n",
        "    for sep in separators:\n",
        "        genre_str = genre_str.replace(sep, \",\")\n",
        "    return set(g.strip() for g in genre_str.split(\",\") if g.strip())\n",
        "\n",
        "df['Normalized_Genre'] = df['Genre'].apply(normalize_genres)\n",
        "\n",
        "# Vectorize synopsis using TF-IDF\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df['Synopsis'].astype(str))\n",
        "\n",
        "# Cosine similarity matrix\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Helper: Get all entries matching the user's title\n",
        "def get_matching_titles(user_title):\n",
        "    user_title = user_title.strip().lower()\n",
        "    matches = df[df['Title'].str.lower() == user_title]\n",
        "    if matches.empty:\n",
        "        # Try loose matches\n",
        "        matches = df[df['Title'].str.lower().str.contains(user_title)]\n",
        "    return matches\n",
        "\n",
        "# Helper: Recommend titles based on selected index and content type\n",
        "def get_recommendations(selected_index, extra_genre, min_rating, num_recs, content_type):\n",
        "    original = df.iloc[selected_index]\n",
        "    original_title = original['Title'].strip().lower()\n",
        "    original_release = original['Release Date']\n",
        "    original_genres = original['Normalized_Genre']\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim[selected_index]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    recommendations = []\n",
        "    seen_entries = set()\n",
        "\n",
        "\n",
        "    # Filter recommendations based on content type (Movie, TV Show, or Both)\n",
        "    for idx, score in sim_scores[1:]:  # Start from index 1 to skip the original\n",
        "        row = df.iloc[idx]\n",
        "        row_title = row['Title'].strip().lower()\n",
        "        row_release = row['Release Date']\n",
        "        row_type = row['Type'].lower()\n",
        "\n",
        "        # Skip if same title and release date as original\n",
        "        if row_title == original_title and row_release == original_release:\n",
        "            continue\n",
        "\n",
        "        entry_key = (row_title, row_release)\n",
        "        if entry_key in seen_entries:\n",
        "            continue\n",
        "\n",
        "\n",
        "        row_genres = row['Normalized_Genre']\n",
        "        if not original_genres.issubset(row_genres):\n",
        "            continue\n",
        "\n",
        "        if extra_genre:\n",
        "            if extra_genre.lower().strip() not in row_genres:\n",
        "                continue\n",
        "\n",
        "        try:\n",
        "            if float(row['Rating']) < min_rating:\n",
        "                continue\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        # Filter by content type\n",
        "        if content_type != 'both' and content_type != row_type:\n",
        "            continue\n",
        "\n",
        "        seen_entries.add(entry_key)\n",
        "\n",
        "\n",
        "        recommendations.append({\n",
        "            \"Title\": row['Title'],\n",
        "            \"Release Date\": row['Release Date'],\n",
        "            \"Rating\": row['Rating'],\n",
        "            \"Genre\": row['Genre'],\n",
        "            \"Popularity\": row['Popularity'],\n",
        "            \"Synopsis\": row['Synopsis'],\n",
        "            \"Content Link\": row['Content Link'],\n",
        "            \"Type\": row['Type'],\n",
        "            \"Actors\": row['Actors'],\n",
        "            \"Directors\": row['Directors']\n",
        "        })\n",
        "\n",
        "        if len(recommendations) >= num_recs:\n",
        "            break\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# ... (original imports and code up to get_recommendations unchanged)\n",
        "\n",
        "# New Helper: Get additional recs based on shared actors or directors\n",
        "def get_shared_cast_recommendations(selected_index, max_results=10):\n",
        "    original = df.iloc[selected_index]\n",
        "    original_title = original['Title'].strip().lower()\n",
        "    original_release = original['Release Date']\n",
        "    original_actors = set(actor.strip().lower() for actor in original['Actors'].split(\",\") if actor.strip())\n",
        "    original_directors = set(d.strip().lower() for d in original['Directors'].split(\",\") if d.strip())\n",
        "\n",
        "    recs = []\n",
        "    seen = set()\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        if i == selected_index:\n",
        "            continue\n",
        "\n",
        "        title = row['Title'].strip().lower()\n",
        "        release = row['Release Date']\n",
        "        if title == original_title and release == original_release:\n",
        "            continue\n",
        "\n",
        "        # Check for shared actors or directors\n",
        "        row_actors = set(actor.strip().lower() for actor in row['Actors'].split(\",\") if actor.strip())\n",
        "        row_directors = set(d.strip().lower() for d in row['Directors'].split(\",\") if d.strip())\n",
        "\n",
        "        shared_actor = original_actors.intersection(row_actors)\n",
        "        shared_director = original_directors.intersection(row_directors)\n",
        "\n",
        "        if shared_actor or shared_director:\n",
        "            key = f\"{title}_{release}\"\n",
        "            if key in seen:\n",
        "                continue\n",
        "            seen.add(key)\n",
        "            recs.append({\n",
        "                \"Title\": row['Title'],\n",
        "                \"Release Date\": row['Release Date'],\n",
        "                \"Rating\": row['Rating'],\n",
        "                \"Genre\": row['Genre'],\n",
        "                \"Popularity\": row['Popularity'],\n",
        "                \"Synopsis\": row['Synopsis'],\n",
        "                \"Content Link\": row['Content Link'],\n",
        "                \"Type\": row['Type'],\n",
        "                \"Actors\": row['Actors'],\n",
        "                \"Directors\": row['Directors'],\n",
        "                \"Shared With\": \"Actors\" if shared_actor else \"Directors\"\n",
        "            })\n",
        "        if len(recs) >= max_results:\n",
        "            break\n",
        "\n",
        "    return recs\n",
        "\n",
        "\n",
        "def step2_generate(selected_index, extra_genre, min_rating, num_recs, content_type):\n",
        "    recs = get_recommendations(selected_index, extra_genre, min_rating, num_recs, content_type)\n",
        "    if not recs:\n",
        "        return \"No recommendations found with these filters.\"\n",
        "\n",
        "    original = df.iloc[selected_index]\n",
        "    original_title = original['Title'].strip().lower()\n",
        "    original_actors = set(a.strip().lower() for a in str(original['Actors']).split(',') if a.strip())\n",
        "    original_directors = set(d.strip().lower() for d in str(original['Directors']).split(',') if d.strip())\n",
        "\n",
        "    def format_names(name_set):\n",
        "        return ', '.join(name.title() for name in sorted(name_set))\n",
        "\n",
        "    display = \"### ðŸŽ¯ **Top Content-Based Recommendations:**\\n\\n\"\n",
        "    for i, rec in enumerate(recs, 1):\n",
        "        display += f\"**{i}. {rec['Title']} ({rec['Release Date']})**\\n\"\n",
        "        display += f\"- Genre: {rec['Genre']}\\n\"\n",
        "        display += f\"- Rating: {rec['Rating']}\\n\"\n",
        "        display += f\"- Synopsis: {rec['Synopsis'][:300]}...\\n\"\n",
        "        display += f\"- Link: {rec['Content Link']}\\n\\n\"\n",
        "\n",
        "    # Helper to track matches\n",
        "    actor_matches = []\n",
        "    director_matches = []\n",
        "    seen_titles = set([original_title])  # Start with original title to avoid showing it again\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        row_title = row['Title'].strip()\n",
        "        row_lower_title = row_title.lower()\n",
        "        if row_lower_title in seen_titles:\n",
        "            continue\n",
        "\n",
        "        actors = set(a.strip().lower() for a in str(row['Actors']).split(',') if a.strip())\n",
        "        directors = set(d.strip().lower() for d in str(row['Directors']).split(',') if d.strip())\n",
        "\n",
        "        shared_actors = original_actors.intersection(actors)\n",
        "        shared_directors = original_directors.intersection(directors)\n",
        "\n",
        "        if shared_actors:\n",
        "            actor_matches.append((len(shared_actors), row, shared_actors))\n",
        "        if shared_directors:\n",
        "            director_matches.append((len(shared_directors), row, shared_directors))\n",
        "\n",
        "        seen_titles.add(row_lower_title)\n",
        "\n",
        "    # Sort and take top 10\n",
        "    # Sort by popularity (higher = more popular)\n",
        "    top_actor_matches = sorted(\n",
        "        actor_matches,\n",
        "        key=lambda x: -float(x[1]['Popularity']) if str(x[1]['Popularity']).replace('.', '', 1).isdigit() else 0\n",
        "    )[:10]\n",
        "\n",
        "    top_director_matches = sorted(\n",
        "    director_matches,\n",
        "    key=lambda x: -float(x[1]['Popularity']) if str(x[1]['Popularity']).replace('.', '', 1).isdigit() else 0\n",
        "    )[:10]\n",
        "\n",
        "\n",
        "    display += \"---\\n\\n### ðŸŽ­ **Top 10 Recommendations (Shared Actors):**\\n\\n\"\n",
        "    for count, row, shared in top_actor_matches:\n",
        "        display += f\"**{row['Title']} ({row['Release Date']})**\\n\"\n",
        "        display += f\"- Shared Actor(s): {format_names(shared)}\\n\"\n",
        "        display += f\"- Rating: {row['Rating']}\\n\"\n",
        "        display += f\"- Synopsis: {row['Synopsis'][:300]}...\\n\"\n",
        "        display += f\"- Link: {row['Content Link']}\\n\\n\"\n",
        "\n",
        "    display += \"---\\n\\n### ðŸŽ¬ **Top 10 Recommendations (Shared Directors):**\\n\\n\"\n",
        "    for count, row, shared in top_director_matches:\n",
        "        display += f\"**{row['Title']} ({row['Release Date']})**\\n\"\n",
        "        display += f\"- Shared Director(s): {format_names(shared)}\\n\"\n",
        "        display += f\"- Rating: {row['Rating']}\\n\"\n",
        "        display += f\"- Synopsis: {row['Synopsis'][:300]}...\\n\"\n",
        "        display += f\"- Link: {row['Content Link']}\\n\\n\"\n",
        "\n",
        "    return display\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Ask for title input\n",
        "def step1_title_input(user_title):\n",
        "    matches = get_matching_titles(user_title)\n",
        "    if matches.empty:\n",
        "        return f\"No matches found for '{user_title}'\", None\n",
        "\n",
        "    seen_titles = set()\n",
        "    options = []\n",
        "\n",
        "    for i, row in matches.iterrows():\n",
        "        title_key = f\"{row['Title'].strip().lower()}_{row['Release Date']}\"\n",
        "        if title_key in seen_titles:\n",
        "            continue\n",
        "        seen_titles.add(title_key)\n",
        "\n",
        "        label = f\"{row['Title']} ({row['Release Date']}) - {row['Synopsis'][:100]}...\"\n",
        "        options.append((label, i))\n",
        "\n",
        "    if not options:\n",
        "        return \"No unique matches found.\", None\n",
        "\n",
        "    return \"Please select the correct title version:\", gr.update(choices=options)\n",
        "\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"ðŸŽ¬ **Movie/TV Recommendation System**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        title_input = gr.Textbox(label=\"Enter Movie/TV Title\")\n",
        "        title_search_btn = gr.Button(\"Search Title\")\n",
        "\n",
        "    title_status = gr.Markdown()\n",
        "    title_dropdown = gr.Dropdown(label=\"Select the correct version\", choices=[], interactive=True, visible=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        extra_genre_input = gr.Textbox(label=\"Optional: Extra Genre (must also contain original genre)\")\n",
        "        min_rating_slider = gr.Slider(0, 10, value=5.0, label=\"Minimum Rating\")\n",
        "        num_recs_slider = gr.Slider(1, 20, value=10, step=1, label=\"Number of Recommendations\")\n",
        "\n",
        "    with gr.Row():\n",
        "        content_type_input = gr.Radio([\"both\", \"movie\", \"tv show\"], label=\"Content Type\", value=\"both\")\n",
        "\n",
        "    generate_btn = gr.Button(\"Generate Recommendations\")\n",
        "    output = gr.Markdown()\n",
        "\n",
        "    title_search_btn.click(fn=step1_title_input, inputs=title_input, outputs=[title_status, title_dropdown])\n",
        "    generate_btn.click(fn=step2_generate,\n",
        "                       inputs=[title_dropdown, extra_genre_input, min_rating_slider, num_recs_slider, content_type_input],\n",
        "                       outputs=output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "ODOcLnn4jisE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "91187627-d077-49df-b496-24781c638d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a1576e504da5d256e1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a1576e504da5d256e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RecommenderSystem ---- Video Game\n"
      ],
      "metadata": {
        "id": "JcvBhW_VuVFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gspread gspread_dataframe oauth2client gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ56Y_F2j0IX",
        "outputId": "0b2a63d0-a778-4e81-edba-36c4e99a444a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.28.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (1.17.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (4.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->oauth2client) (3.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from gspread_dataframe import get_as_dataframe\n",
        "import pandas as pd\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from difflib import get_close_matches"
      ],
      "metadata": {
        "id": "XNXN-v5Yulzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important Notice\n",
        "This application requires access to a private Google Sheet containing the scraped game dataset.\n",
        "load_googlesheet\n",
        "To successfully run the code, you must:\n",
        "* Have a Google service account with permission to access the target Google Sheet.\n",
        "* Ensure the service account email is added as a viewer/editor to the Google Sheet.\n",
        "* Only works inside Google Colab, uses Colab's built-in user authentication flow\n",
        "* If wants to run on other enviroment, need to place the credentials JSON file in your project directory and authenticate using it before calling **load_googlesheet()**\n",
        "***load_googlesheet()** requires to modify:\n",
        "\n",
        "      from google.oauth2.service_account import Credentials\n",
        "\n",
        "      creds = Credentials.from_service_account_file('your_credentials.json')\n",
        "\n",
        "      client = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "eD9kCvFRuZA8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions\n",
        "This section provides the full function model for a recommender system.\n",
        "\n",
        "**load_googlesheet function** is used to access and load scraped game data. This function connects to a specific Google Sheet using the gspread and pandas libraries to retrieve up-to-date information used in the recommender system.\n",
        "\n",
        "Instruction:\n",
        "1. Ensure that you have authorized access to the Google Sheet by generating and downloading a service account credentials file.\n",
        "2. Copy and paste the google sheet link, and the sheet tab name into variables.\n",
        "3. Run the load_googlesheet() function to retrieve the dataset into a DataFrame.\n",
        "   Example: df = load_googlesheet(sheet_url, worksheet_name)\n",
        "4. Returned df should contain all the columns of the googlesheet.\n",
        "\n",
        "Notes:\n",
        "If you modify the structure of the Google Sheet, ensure that the load_googlesheet function is updated accordingly to maintain compatibility.\n",
        "\n",
        "\n",
        "**parse_owner function** is used to transform the owners column from the game dataset.  The owners column displayed as something like (\"20,000 - 50,000\") in the dataset. To make this column can be easily use for analysis, this function will convert the values into a single averaged value.  \n",
        "\n",
        "Instruction:\n",
        "1. Create a new column named 'owners_avg', and called apply function to apply the parse_owners function to the owners column.\n",
        " Example : df['owners_avg'] = df['owners'].apply(parse_owners)\n",
        "\n",
        "Notes:\n",
        "Ensure that the owners column has valid range strings. If the format varies, additional error handling might be needed.  \n",
        "If there are missing or invalid entries (e.g., \"N/A\"), consider handling those separately before applying this function.\n",
        "\n",
        "**get_closest_title(title)** is used to help users find the most similar game title from the dataset, in case they make a typo or enter a slightly incorrect name.\n",
        "*   n = number of matches to be returned, default set as 1, can be modified to receive a list of titles\n",
        "*   cutoff = minimum similarity threshold, default set as 0.7, can be modify\n",
        "\n",
        "How it works:\n",
        "*   Uses Python's difflib.get_close_matches to compare the input title to known game titles (indices.index)\n",
        "*   if a close match (with similarity score greater than 0.65) is found, it returns that title\n",
        "*   If no match is found, returns None.\n",
        "\n",
        "\n",
        "**Recommend_games(title, num_recommendations=10)** is a basic recommender system model that recommends similar games based on text similarity, using TF-IDF and cosine similairty on the combination of game description,genres and tags\n",
        "\n",
        "Parameters:\n",
        "* titile = game title\n",
        "* num_recommendations = number of recommendation that user's want to generate, default set to 10 output.\n",
        "How it works:\n",
        "1. Checks if the given title exists in the dataset(indices). If not found, then return error message\n",
        "2. Finds the similarity score between the given title and others using a precomputed cosine similarity matrix (cosine_sim)\n",
        "3. Sorts the games by similarity score (from highest to lowest)\n",
        "4. Returns the top n most similarity games\n",
        "\n",
        "**Recommend_hybrid(title, num_recommendations=10)** is a hybrid recommender system model that combining the similarity with popularity metrics\n",
        "Parameters:\n",
        "titile = game title\n",
        "num_recommendations = number of recommendation that user's want to generate, default set to 10 output.\n",
        "How it works:\n",
        "1. Checks if the given title exists in the dataset(indices). If not found, then return error message\n",
        "2. Gets content-based similarity scores\n",
        "3. Combines similarty score with popularity score uisng a weighted average, can be modified:\n",
        "  * similarity weight = 75%\n",
        "  * popularity weight = 25%\n",
        "  * **caution: if popularity score weighted too high, the output will have bias because some of the video games such as CSGO have a very large popularity score, and will significant impact the recommendation**\n",
        "4. Output dataframe: game title, genre, tags, popularity score, current players, peak player of the day, review counts(positive/negative), short_description"
      ],
      "metadata": {
        "id": "NG_MNu-FuvWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_googlesheet(sheet_url, worksheet_name):\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "    client = gspread.authorize(creds)\n",
        "    spreadsheet = client.open_by_url(sheet_url)\n",
        "    worksheet = spreadsheet.worksheet(worksheet_name)\n",
        "    df = get_as_dataframe(worksheet)\n",
        "    df = df.dropna(how='all')\n",
        "    return df\n",
        "\n",
        "sheet_url = \"https://docs.google.com/spreadsheets/d/1J5NcGXWvWs7NNLKJw96WVKjMKN8Dno0Wk2ohYbjJLZY\"\n",
        "worksheet_name = \"Cleaned_game_details\"\n",
        "df = load_googlesheet(sheet_url, worksheet_name)\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df['combined_features'])\n",
        "\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "indices = pd.Series(df.index, index=df['name']).drop_duplicates()\n",
        "\n",
        "def parse_owners(owner_range):\n",
        "    try:\n",
        "        parts = owner_range.replace(',', '').split('-')\n",
        "        low = int(parts[0].strip())\n",
        "        high = int(parts[1].strip())\n",
        "        return (low + high) // 2\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "df['owners_avg'] = df['owners'].apply(parse_owners)\n",
        "for col in ['Peak_Today', 'Current_Players', 'owners', 'positive', 'negative']:\n",
        "    df[col] = df[col].fillna(0)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df[['peak_score', 'player_score', 'owner_score', 'pos_score', 'neg_score']] = scaler.fit_transform(\n",
        "    df[['Peak_Today', 'Current_Players', 'owners_avg', 'positive', 'negative']]\n",
        ")\n",
        "df['popularity_score'] = (\n",
        "    0.3 * df['peak_score'] +\n",
        "    0.2 * df['player_score'] +\n",
        "    0.2 * df['owner_score'] +\n",
        "    0.2 * df['pos_score'] -\n",
        "    0.1 * df['neg_score']\n",
        ")\n",
        "\n",
        "def get_closest_title(title):\n",
        "    matches = get_close_matches(title, indices.index, n=1, cutoff=0.7)\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "def recommend_games(title, num_recommendations=10):\n",
        "    if title not in indices:\n",
        "        return None, f\"'{title}' not found.\"\n",
        "\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:num_recommendations+1]\n",
        "\n",
        "    game_indices = [i[0] for i in sim_scores]\n",
        "    return df.iloc[game_indices].copy().assign(score=[x[1] for x in sim_scores]), None\n",
        "\n",
        "def recommend_hybrid(title, num_recommendations=10):\n",
        "    if title not in indices:\n",
        "        return None, f\"'{title}' not found in dataset.\"\n",
        "\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "def recommend_hybrid(title, num_recommendations=10):\n",
        "    if title not in indices:\n",
        "        return None, f\"'{title}' not found in dataset.\"\n",
        "\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Use weighted blend instead of multiplication\n",
        "    hybrid_scores = [\n",
        "        (i, 0.75 * sim + 0.25 * df.iloc[i]['popularity_score']) for i, sim in sim_scores if i != idx\n",
        "    ]\n",
        "\n",
        "    # Sort and select top results\n",
        "    hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)\n",
        "    top_indices = [i[0] for i in hybrid_scores[:num_recommendations]]\n",
        "\n",
        "    # Return your preferred columns + relevance score\n",
        "    result_df = df.loc[top_indices, ['name', 'genre', 'tags', 'popularity_score', 'Current_Players', 'Peak_Today', 'positive', 'negative', 'short_description']].copy()\n",
        "    result_df['score'] = [x[1] for x in hybrid_scores[:num_recommendations]]\n",
        "\n",
        "    return result_df, None"
      ],
      "metadata": {
        "id": "eLTZqaPPurCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interative Dashboard\n",
        "This section creates a web-based user interface using Gradio, allowing users to personalize the game recommendations by selecting between basic and hybrid models and applying filters.\n",
        "\n",
        "\n",
        "**Recommend_interface()** function serves as the controller for the filtering and formatted outputs.\n",
        "\n",
        "Parameters:\n",
        "* title: Game title input by user.\n",
        "* num_recommendations: Number of games to recommend (5â€“20).\n",
        "* mode: Recommendation strategy â€” \"Content-based\" or \"Hybrid\".\n",
        "* selected_genres: Optional list of genres to filter results.\n",
        "* min_popularity: Minimum popularity score threshold.\n",
        "* min_positive: Minimum number of positive reviews.\n",
        "How it works:\n",
        "1. if the title is not found, attempts matching using **get_close_matches()**\n",
        "2. Calls either **recommend_games()** or **recommend_hybrid()** depending on the user selection\n",
        "3. Filters the result set by selected genres (if any), popularity score, and positive reviews.\n",
        "4. Construct a readable markdown block for each game, includes genre, popularity, peak players, reviews, relevance score, short description if available\n",
        "5. Return the results inside a scrollable window, if no games meet criteria returns a message.\n",
        "\n",
        "\n",
        "Before launching the interface, make sure genres are cleaned and prepared as a dropdown filter\n",
        "\n",
        "**gr.Interface()** function powered the dashboard interface and displays the recommendation based on users customization.\n",
        "\n",
        "Inputs:\n",
        "* Textbox: Game title (default: Cities: Skylines)\n",
        "* Slider: Number of recommendations (5â€“20)\n",
        "* Radio: Recommendation mode (Content-based or Hybrid)\n",
        "* Dropdown: Genre filter (multi-select enabled)\n",
        "* Slider: Minimum popularity score (0.0â€“1.0)\n",
        "* Slider: Minimum number of positive reviews\n",
        "\n",
        "Output: Displays recommendation results with text and optional image"
      ],
      "metadata": {
        "id": "VnAQLU2fvFkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from difflib import get_close_matches\n",
        "\n",
        "# Clean genre list for dropdown\n",
        "all_genres = df['genre'].dropna().str.split(',')\n",
        "flat_genres = all_genres.explode().str.strip()\n",
        "unique_genres = sorted(flat_genres.unique())\n",
        "\n",
        "# Main recommender interface function\n",
        "def recommend_interface(title, num_recommendations, mode, selected_genres, min_popularity, min_positive):\n",
        "    try:\n",
        "        if title not in indices:\n",
        "            matches = get_close_matches(title, indices.index, n=1, cutoff=0.6)\n",
        "            if matches:\n",
        "                title = matches[0]\n",
        "            else:\n",
        "                return \"Game not found.\"\n",
        "\n",
        "        if mode == \"Content-based\":\n",
        "            results, _ = recommend_games(title, num_recommendations)\n",
        "        else:\n",
        "            results, _ = recommend_hybrid(title, num_recommendations)\n",
        "\n",
        "        if results is None or isinstance(results, str):\n",
        "            return \"No results found.\"\n",
        "\n",
        "        # Filters\n",
        "        if selected_genres:\n",
        "            results = results[results['genre'].apply(\n",
        "                lambda g: any(genre in g for genre in selected_genres)\n",
        "            )]\n",
        "        results = results[\n",
        "            (results['popularity_score'] >= min_popularity) &\n",
        "            (results['positive'] >= min_positive)\n",
        "        ]\n",
        "\n",
        "        if results.empty:\n",
        "            return \"No recommendations match your filters.\"\n",
        "\n",
        "        # Output formatting\n",
        "        output = \"\"\n",
        "        for _, row in results.iterrows():\n",
        "            output += f\"\"\" ðŸŽ® {row['name']}\\n\n",
        "**Genre:** {row.get('genre', 'N/A')}\\n\n",
        "**Tags:** {row.get('tags', 'N/A')}\\n\n",
        "**Popularity Score:** {row.get('popularity_score', 0):.2f}\\n\n",
        "**Peak Today:** {row.get('Peak_Today', 0)}\\n\n",
        "**Positive Reviews:** {row.get('positive', 0)}\\n\n",
        "**Relevance Score:** {row.get('score', 0):.4f}\\n\n",
        "\"\"\"\n",
        "            if 'short_description' in row and isinstance(row['short_description'], str):\n",
        "                output += f\"{row['short_description']}\\n\\n\"\n",
        "            if 'header_image_url' in row and isinstance(row['header_image_url'], str):\n",
        "                output += f\"![Game Image]({row['header_image_url']})\\n\\n\"\n",
        "            output += \"---\\n\"\n",
        "\n",
        "        # Wrap in scrollable div\n",
        "        scroll_wrapper = f\"\"\"\n",
        "<div style=\"max-height: 600px; overflow-y: auto; padding-right: 10px;\">\n",
        "{output}\n",
        "</div>\n",
        "\"\"\"\n",
        "        return scroll_wrapper\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Launch Gradio interface\n",
        "gr.Interface(\n",
        "    fn=recommend_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter a game title\", value=\"Cities: Skylines\"),\n",
        "        gr.Slider(5, 20, value=10, step=1, label=\"Number of Recommendations\"),\n",
        "        gr.Radio([\"Content-based\", \"Hybrid\"], value=\"Hybrid\", label=\"Recommendation Mode\"),\n",
        "        gr.Dropdown(choices=unique_genres, label=\"Select Genres (optional)\", multiselect=True),\n",
        "        gr.Slider(0.0, 1.0, value=0.0, step=0.05, label=\"Minimum Popularity Score\"),\n",
        "        gr.Slider(0, int(df['positive'].max()), value=0, step=1000, label=\"Minimum Positive Reviews\"),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Recommendations\"),\n",
        "    title=\"ðŸŽ® Game Recommender\",\n",
        "    description=\"Discover games based on content similarity and popularity. Filter by genre, reviews, and more!\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "id": "CAXG6DZgvCqp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "e203b3e9-dd3a-4524-ae95-ce97ecba946b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8838eba899e0225bc3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8838eba899e0225bc3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Successes and Failures of our Recommender Systems\n",
        "\n",
        "This section is mainly for interns who want to take over this project and improve on the existing models.\n",
        "\n",
        "https://docs.google.com/document/d/17iQQPQWxp-NsMrdwiiMe6mz_K0F3ygvKkj7D_XZG7Rs/edit?usp=drive_link"
      ],
      "metadata": {
        "id": "WwPrYWVJNRA3"
      }
    }
  ]
}